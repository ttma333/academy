{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/sentence_generation/deploy_colab1.ipynb","timestamp":1673055831508}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"8f8d1bbdf1a54fa29be2b2e37a09ec51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72a4a2cdfb21403b8562fba94628e7e4","IPY_MODEL_dec93915198449ada895f9e52752077b","IPY_MODEL_92f8fa36186b490fbe619ef3d3c01eff"],"layout":"IPY_MODEL_66f4c5f394964089b063fc6e231a3f3d"}},"72a4a2cdfb21403b8562fba94628e7e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e494bcf80fa4ee2840ab43651136a8f","placeholder":"​","style":"IPY_MODEL_264f399cd94c41ae86eb5e15606417b4","value":"Downloading: 100%"}},"dec93915198449ada895f9e52752077b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71a9eeb48b3a480eb8e5314dfc595b40","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69d985cead944e8d82e19ba842c19bc2","value":2825034}},"92f8fa36186b490fbe619ef3d3c01eff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daff47208a9747168e2340f9f474d2ee","placeholder":"​","style":"IPY_MODEL_3290fac2b11a4afb8a5627c2aedbeeca","value":" 2.83M/2.83M [00:00&lt;00:00, 41.4MB/s]"}},"66f4c5f394964089b063fc6e231a3f3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e494bcf80fa4ee2840ab43651136a8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"264f399cd94c41ae86eb5e15606417b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71a9eeb48b3a480eb8e5314dfc595b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d985cead944e8d82e19ba842c19bc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"daff47208a9747168e2340f9f474d2ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3290fac2b11a4afb8a5627c2aedbeeca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1490870e7a1243ecb29cbbe98d20140d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c5c0cf3a8cd4808be3347e3a2fb60e7","IPY_MODEL_971a9745054f4aa395948544355161ba","IPY_MODEL_5ee46c46c29846f6ac15f6925fbab1e3"],"layout":"IPY_MODEL_202c0bd6221e4895be3802bf30758c50"}},"2c5c0cf3a8cd4808be3347e3a2fb60e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55de69edafd94ac9a4772642c20ede0f","placeholder":"​","style":"IPY_MODEL_c7a52f47a672472282335ba017daf928","value":"Downloading: 100%"}},"971a9745054f4aa395948544355161ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c21184d4754c35b8830fbbaea79944","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1019af7314fe4218bfec817f23f83db6","value":1000}},"5ee46c46c29846f6ac15f6925fbab1e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73a3f0b2d44240d1ba4fa710141edac8","placeholder":"​","style":"IPY_MODEL_0174fdb9f7a947e7b6c5fe0ab70a0e36","value":" 1.00k/1.00k [00:00&lt;00:00, 61.5kB/s]"}},"202c0bd6221e4895be3802bf30758c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55de69edafd94ac9a4772642c20ede0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7a52f47a672472282335ba017daf928":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c21184d4754c35b8830fbbaea79944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1019af7314fe4218bfec817f23f83db6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"73a3f0b2d44240d1ba4fa710141edac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0174fdb9f7a947e7b6c5fe0ab70a0e36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb2d64a1dfc64cb5808e88ae3f27bebf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6df9b6721f6d40fba94075cdd21fd7ba","IPY_MODEL_67976b158924416e9f0e65bd33eab672","IPY_MODEL_fb2033e3a3e34f498b35ce8afdb86400"],"layout":"IPY_MODEL_e41a6eead9d54274a1e3b7ae6cb5d26b"}},"6df9b6721f6d40fba94075cdd21fd7ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd3653e3284a4496b447c5f8f1459d6a","placeholder":"​","style":"IPY_MODEL_d9397d8e9a0247a5a6c9374b51c902fe","value":"Downloading: 100%"}},"67976b158924416e9f0e65bd33eab672":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_935aec6c8fc74810ba3fce79eb5ee28f","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6dc6b2df4143406b9bf1f8db2c8f3f98","value":513302779}},"fb2033e3a3e34f498b35ce8afdb86400":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bf04dc8dbc647879403920b75eb2d57","placeholder":"​","style":"IPY_MODEL_6dceba51c3724c65ad40d8f866999f89","value":" 513M/513M [00:07&lt;00:00, 74.7MB/s]"}},"e41a6eead9d54274a1e3b7ae6cb5d26b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd3653e3284a4496b447c5f8f1459d6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9397d8e9a0247a5a6c9374b51c902fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"935aec6c8fc74810ba3fce79eb5ee28f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc6b2df4143406b9bf1f8db2c8f3f98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bf04dc8dbc647879403920b75eb2d57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dceba51c3724c65ad40d8f866999f89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"8oaGGhdmYKqt"},"source":["# 패키지 설치\n","pip 명령어로 의존성 있는 패키지를 설치합니다.\n","\n"]},{"cell_type":"code","metadata":{"id":"t8TJkXkpDnSq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674002389945,"user_tz":-540,"elapsed":12367,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"3ac7edfb-5eb8-4482-b088-71259edb33c3"},"source":["!pip install ratsnlp"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ratsnlp\n","  Downloading ratsnlp-1.0.52-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.10.0\n","  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flask>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from ratsnlp) (1.1.4)\n","Collecting flask-ngrok>=0.0.25\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Collecting flask-cors>=3.0.10\n","  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n","Collecting Korpora>=0.2.0\n","  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-lightning==1.6.1\n","  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 KB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.4.0)\n","Collecting pyDeprecate<0.4.0,>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.13.1+cu116)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (4.64.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (21.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2.9.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (2022.11.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (1.21.6)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1->ratsnlp) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0->ratsnlp) (3.9.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0->ratsnlp) (2.25.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0->ratsnlp) (2022.6.2)\n","Collecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask>=1.1.4->ratsnlp) (7.1.2)\n","Requirement already satisfied: Six in /usr/local/lib/python3.8/dist-packages (from flask-cors>=3.0.10->ratsnlp) (1.15.0)\n","Collecting dataclasses>=0.6\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from Korpora>=0.2.0->ratsnlp) (1.2.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (3.8.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.1.4->ratsnlp) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch-lightning==1.6.1->ratsnlp) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.10.0->ratsnlp) (2022.12.7)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.19.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.4.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.51.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.38.4)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (2.16.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.10.0->ratsnlp) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.1->ratsnlp) (22.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (5.2.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (6.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.11.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.1->ratsnlp) (3.2.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=664a8f1a278478f907af3dcbef480fab537034209595a986120deb3245fd8ede\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, dataclasses, sacremoses, pyDeprecate, torchmetrics, Korpora, huggingface-hub, transformers, flask-ngrok, flask-cors, pytorch-lightning, ratsnlp\n","Successfully installed Korpora-0.2.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 huggingface-hub-0.11.1 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 ratsnlp-1.0.52 sacremoses-0.0.53 tokenizers-0.10.3 torchmetrics-0.11.0 transformers-4.10.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"J3mThtbxyNyO"},"source":["# 모델 로딩\n","프리트레인한 GPT2 모델과 토크나이저를 읽어 들입니다."]},{"cell_type":"code","metadata":{"id":"aFV031RZFRgD","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1490870e7a1243ecb29cbbe98d20140d","2c5c0cf3a8cd4808be3347e3a2fb60e7","971a9745054f4aa395948544355161ba","5ee46c46c29846f6ac15f6925fbab1e3","202c0bd6221e4895be3802bf30758c50","55de69edafd94ac9a4772642c20ede0f","c7a52f47a672472282335ba017daf928","e7c21184d4754c35b8830fbbaea79944","1019af7314fe4218bfec817f23f83db6","73a3f0b2d44240d1ba4fa710141edac8","0174fdb9f7a947e7b6c5fe0ab70a0e36","cb2d64a1dfc64cb5808e88ae3f27bebf","6df9b6721f6d40fba94075cdd21fd7ba","67976b158924416e9f0e65bd33eab672","fb2033e3a3e34f498b35ce8afdb86400","e41a6eead9d54274a1e3b7ae6cb5d26b","cd3653e3284a4496b447c5f8f1459d6a","d9397d8e9a0247a5a6c9374b51c902fe","935aec6c8fc74810ba3fce79eb5ee28f","6dc6b2df4143406b9bf1f8db2c8f3f98","8bf04dc8dbc647879403920b75eb2d57","6dceba51c3724c65ad40d8f866999f89"]},"executionInfo":{"status":"ok","timestamp":1674002448163,"user_tz":-540,"elapsed":16806,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"738db271-ea5d-448d-b830-a59d72bf25cc"},"source":["from transformers import GPT2LMHeadModel\n","model = GPT2LMHeadModel.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n",")\n","model.eval()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1490870e7a1243ecb29cbbe98d20140d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2d64a1dfc64cb5808e88ae3f27bebf"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"C3amlsjpFd9i","colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["8f8d1bbdf1a54fa29be2b2e37a09ec51","72a4a2cdfb21403b8562fba94628e7e4","dec93915198449ada895f9e52752077b","92f8fa36186b490fbe619ef3d3c01eff","66f4c5f394964089b063fc6e231a3f3d","5e494bcf80fa4ee2840ab43651136a8f","264f399cd94c41ae86eb5e15606417b4","71a9eeb48b3a480eb8e5314dfc595b40","69d985cead944e8d82e19ba842c19bc2","daff47208a9747168e2340f9f474d2ee","3290fac2b11a4afb8a5627c2aedbeeca"]},"executionInfo":{"status":"ok","timestamp":1673413231880,"user_tz":-540,"elapsed":1080,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"64494a4c-a8d2-4da3-e148-a197e30261f4"},"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\n","    \"skt/kogpt2-base-v2\",\n","    eos_token=\"</s>\",\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8d1bbdf1a54fa29be2b2e37a09ec51"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]}]},{"cell_type":"markdown","metadata":{"id":"B_b-3ZCPNQ5p"},"source":["## 프롬프트 준비\n","\n","언어모델에 넣을 프롬프트를 준비합니다."]},{"cell_type":"code","metadata":{"id":"VhGrFki_M6CT"},"source":["input_ids = tokenizer.encode(\"안녕하세요\", return_tensors=\"pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ByRsPyb1hfiJ","executionInfo":{"status":"ok","timestamp":1673413238637,"user_tz":-540,"elapsed":4,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"4bf3ac64-e8d6-4d0b-8134-ac78312ec7a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[25906,  8702,  7801,  8084]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"j0yIwXhDNl7i"},"source":["## Greedy Search\n","\n","\n","다음 단어 확률 분포에서 최대 확률을 내는 단어들을 리턴합니다. \n","여러 번 수행하더라도 생성 결과가 바뀌지 않습니다 (`do_sample=False`).\n","`max_length`는 생성 최대 길이이며 이보다 길거나, 짧더라도 EOD 토큰 등 스페셜 토큰이 나타나면 생성을 중단합니다. `min_length`는 생성 최소 길이이며 이보다 짧은 구간에서 EOD 등 스페셜 토큰이 등장해 생성이 중단될 경우 해당 토큰이 나올 확률을 0으로 수정하여 문장 생성이 종료되지 않도록 강제합니다."]},{"cell_type":"code","metadata":{"id":"J94NJQRHM9sA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673421463766,"user_tz":-540,"elapsed":736,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"5a8f3cb6-6f2a-455f-a440-288d683d534a"},"source":["import torch\n","with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=15,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요\n"]}]},{"cell_type":"markdown","metadata":{"id":"LlpAZmbVQ0FN"},"source":["## Beam Search \n","\n","Beam Search는 다음 단어 확률 분포에서 `num_beams`만큼의 경우의 수를 남겨가면서 문장을 생성합니다. Beam search는 Greedy search보다 계산량이 많지만 좀 더 확률값이 높은 문장을 생성할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"8ZMWKWTyRLA4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673421590707,"user_tz":-540,"elapsed":3098,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"972829ee-9b71-4816-bc17-5cec80f0301c"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        num_beams=3, # 빔 크기 변경\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그렇지 않습니다.\"\n","\"그렇지 않습니다.\"\n","\"그렇지 않습니다.\"\n","\"그렇지 않습니다.\"\n","\"그렇지 않습니다.\"\n","\"그렇지 않습니다.\"\n","\"그\n"]}]},{"cell_type":"markdown","metadata":{"id":"7SJsuYFKREfp"},"source":["`num_beams=1`로 설정하면 정확히 Greedy search와 동일하게 작동합니다.\n"]},{"cell_type":"code","metadata":{"id":"yAioTRj3SuhA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673416152986,"user_tz":-540,"elapsed":2006,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"9202e49a-25fb-4461-e827-a60820ed6161"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        num_beams=1,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"VoVeZTxtQDpU"},"source":["## 반복 줄이기\n","\n","### 반복되는 n-gram 사이즈를 지정하기\n","\n","위의 예시를 보면 `\"그럼, 그건 뭐예요?\"`이 반복됩니다. 이를 아래와 같이 지정해 반복을 방지합니다. 3개 이상의 토큰이 반복될 경우 해당 3-gram 등장 확률을 0으로 만들어 생성 결과에서 배제합니다.\n"]},{"cell_type":"code","metadata":{"id":"a7-ixOKZQYmb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673421894305,"user_tz":-540,"elapsed":1950,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"151abb15-0e77-4aba-fa0e-64aa7a1c1c34"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        no_repeat_ngram_size=3, # 토큰 3개 이상 반복 시 3번째 토큰 확률 0으로 변경\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\" 하고 나는 물었다.\n","\"그건 뭐죠?\" 나는 물었다.\n","나는 대답하지 않았다.\n","\"그런데 왜 그걸 물어요? 그건 무슨 뜻이에요?\n"]}]},{"cell_type":"markdown","metadata":{"id":"6KMSLJm6QnqW"},"source":["### repetition penalty\n","\n","repetition penalty로 반복을 통제할 수도 있습니다. 다음과 같이 실행하면 되며 그 범위는 1 이상의 값을 가져야 합니다. 1이라면 아무런 패널티를 적용하지 않는게 됩니다.\n"]},{"cell_type":"code","metadata":{"id":"9-E8zQaKaI0Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673421957831,"user_tz":-540,"elapsed":1967,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"0028f9a2-8bbc-43e2-82c7-e05fb61f1bf4"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        repetition_penalty=1.0, # 리피티션 패널티 적용\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"UA4sIZ3l2UGD"},"source":["`repetition_penalty` 값이 클 수록 패널티가 세게 적용됩니다."]},{"cell_type":"code","metadata":{"id":"KYYEgzc_QnLm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422025330,"user_tz":-540,"elapsed":1901,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"f93dac70-4258-41db-ea86-0cc2424cd5c9"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        repetition_penalty=1.1, # 반복이 점점 줄어드는 경향\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"아니요, 저는요.\"\n","\"그럼, 그건 무슨 말씀이신지요?\"\n","\"그럼, 그건 뭐예요?\"\n","\n"]}]},{"cell_type":"code","metadata":{"id":"BIAHKtfIZ93g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422031131,"user_tz":-540,"elapsed":2047,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"74ae147c-d532-4659-890b-aa315f845f78"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        repetition_penalty=1.2,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요, 아저씨. 저는 지금 이 순간에도 괜찮아요.\"\n","\"그래서 오늘은 제가 할 수 있는 일이 무엇인지 말해 보겠습니다.\"\n","\"이제\n"]}]},{"cell_type":"code","metadata":{"id":"1Qe5hlCgaRAL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422038278,"user_tz":-540,"elapsed":1647,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"b11e3ab9-d173-4bdd-ed07-3e8bd063e7ac"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=False,\n","        min_length=10,\n","        max_length=50,\n","        repetition_penalty=1.5,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요, 아저씨. 저는 지금 이 순간에도 괜찮아요. 그리고 제가 할 수 있는 일은 아무것도 없어요.\n","이제 그만 돌아가고 싶어요.\n","제가 하는 일이 무엇\n"]}]},{"cell_type":"markdown","metadata":{"id":"CG-THCtUd8BP"},"source":["## top-k sampling\n","\n","지금까지는 생성을 반복하더라도 그 결과가 동일한 샘플링 방식을 살펴봤습니다. top-k sampling은 다음 단어를 뽑을 때 확률값 기준 가장 큰 k개 가운데 하나를 선택하는 기법입니다. 확률값이 큰 단어가 다음 단어로 뽑힐 가능성이 높아지지만, k개 안에 있는 단어라면 확률값이 낮더라도 다음 단어로 추출될 수 있습니다. 따라서 top-k sampling은 매 시행 때마다 생성 결과가 달라집니다. k는 1 이상의 값을 지녀야 합니다."]},{"cell_type":"code","metadata":{"id":"hZykqqkLeoGa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422129056,"user_tz":-540,"elapsed":2020,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"51d5dd4d-24f5-4464-ce74-86593c53c290"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_k=50, # 확률값이 가장 높은 k개 토큰 가운데 하나를 다음 토큰으로 선택 \n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"아, 정말 아니지 않아요?\"\n","\"왜! 그건 아니구요.\"\n","\"하하하! 그게 아까부터 알았지. 그러니까 난 이제 와서 저를 미워할 건가!\n"]}]},{"cell_type":"markdown","metadata":{"id":"65_mnOwW219w"},"source":["k=1일 경우 Greedy search와 동일합니다. "]},{"cell_type":"code","metadata":{"id":"_RGBeGUMeoqx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673084131650,"user_tz":-540,"elapsed":2174,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"7b5a50de-56f9-4315-ce33-2b0dec5930c2"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_k=1,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"fnI1PwaSgAN3"},"source":["## top-k sampling + temperature scaling\n","\n","top-k sampling은 temperature scaling과 동시에 적용할 수 있습니다. 그 값에 따라 다음과 같은 효과가 납니다.\n","\n","(1) t가 0에 가까워질 수록 토큰 분포가 sharp해진다 > 1등 토큰이 뽑힐 확률이 그만큼 높아진다 > do_sample=True이지만 사실상 greedy decoding이 된다"]},{"cell_type":"code","metadata":{"id":"OelobEFugAeV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422503246,"user_tz":-540,"elapsed":2258,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"0741a50e-4b03-470d-af32-1e8b71bf2279"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_k=50,\n","        temperature=0.01,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"1u2O8Vfc3IET"},"source":["(2) t=1이라면 모델 출력 분포를 그대로 사용한다 > 하지만 샘플링 방식을 사용하기 때문에 생성할 때마다 다른 문장이 나온다"]},{"cell_type":"code","metadata":{"id":"c-wV6jAdiF_D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422517524,"user_tz":-540,"elapsed":2038,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"458e9461-498e-4006-aa35-51beb7a2088b"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_k=50,\n","        temperature=1.0,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\", \"그렇지 않아요!\", \"그래도 나는 네게 손을 대려고 한다\"며 맞장구를 쳤다.\n","이에 하태경은 \"그러면 안 되지요\"라며 일침했다.\n","뒤늦게 도착한 하태\n"]}]},{"cell_type":"markdown","metadata":{"id":"_qJla1_y3N1y"},"source":["(3) t를 키울수록 토큰 분포가 uniform해진다 > 사실상 uniform sampling이 된다, 생성 품질이 악화할 가능성이 높아진다"]},{"cell_type":"code","metadata":{"id":"LnrgKCxuiMrN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422536142,"user_tz":-540,"elapsed":1942,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"2f2f675c-f1e1-4cc0-8d10-57b523f9f192"},"source":["# 실행할 때마다 다른 문장 생성\n","with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_k=50,\n","        temperature=100000000.0,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요).\n","다행일 것 많은 한식당 카페. 단품으로 예불한다 하더라도 직접 식혜 한봉지만 먹어라고,\n","직원에 물어보지 그랬지, 아 그분에게 뭐 어떠시고 또 어떻게 식당에서 먹일\n"]}]},{"cell_type":"markdown","metadata":{"id":"50bBi6ZRihKw"},"source":["## top-p sampling\n","\n","top-p sampling은 다음 단어를 뽑을 때 누적 확률값이 p 이하인 단어들 가운데 하나를 선택하는 기법입니다. 확률값이 큰 단어가 다음 단어로 뽑힐 가능성이 높아지지만, 누적 확률값 p 이하에 있는 단어라면 확률값이 낮더라도 다음 단어로 추출될 수 있습니다. 따라서 top-p sampling은 매 시행 때마다 생성 결과가 달라집니다. p는 확률이기 때문에 0~1 사이의 값을 지녀야 합니다. p가 1이라면 어휘 집합에 있는 모든 단어를 대상으로 샘플링하기 때문에 top-p sampling 효과가 사라집니다. p가 1보다 약간 작다면 확률값이 낮은 일부 단어들을 다음 단어 후보에서 제거해 생성 품질을 높입니다. "]},{"cell_type":"code","metadata":{"id":"XjNy7gaXkDGn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422584022,"user_tz":-540,"elapsed":2217,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"8700feff-b42c-440d-8e80-9a6f6498a129"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_p=0.92,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?’라는 질문을 던지고 나서 갑자기 고개를 갸우뚱했다.\n","“저는 우리 아버지께서 돌아가신 후 우리 아들들을 위해 목숨을 바치셨다고 생각합니다.” 이 말 한마디에 큰 충격을 받았다.\n","이 말을 듣자 아버지는 큰 충격을 받은\n"]}]},{"cell_type":"markdown","metadata":{"id":"tIws234s4JhR"},"source":["p가 0에 가까울 경우 Greedy search와 비슷해 집니다."]},{"cell_type":"code","metadata":{"id":"kCAgYU3RkZ80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673422588844,"user_tz":-540,"elapsed":2075,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"c84a3bde-e228-4f30-b03b-3d1b2928e192"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        top_p=0.01,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\"그럼, 그건 뭐예요?\"\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"MRR-vy6klf8y"},"source":["## 통합 적용\n","\n","저희가 실습에 사용하고 있는 허깅페이스(huggingface) 라이브러리의 구현상 적용 순서는 다음과 같습니다.\n","\n","- _get_logits_processor\n","  - RepetitionPenalty\n","  - NoRepeatNGramLogits\n","  - MinLengthLogits\n","- _get_logits_warper\n","  - TemperatureLogits\n","  - TopKLogits\n","  - TopPLogits\n","\n","유효한 설정들을 종합 적용해 문장을 생성하는 코드는 다음과 같습니다. 샘플링(top-k, top-p)을 적용하기 때문에 시행 때마다 다른 문장이 생성됩니다."]},{"cell_type":"code","metadata":{"id":"iLo9mtlUmcAK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673418070492,"user_tz":-540,"elapsed":2210,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"5c0ea4a8-394e-4aa4-ebd6-2a5e07248b43"},"source":["with torch.no_grad():\n","    generated_ids = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        min_length=10,\n","        max_length=50,\n","        repetition_penalty=1.5,\n","        no_repeat_ngram_size=3,\n","        temperature=0.9,\n","        top_k=50,\n","        top_p=0.92,\n","    )\n","    print(tokenizer.decode([el.item() for el in generated_ids[0]]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요?\"\n","그녀의 말이 사실일 거라고는 생각도 하지 못했습니다.\n","\"아직까지 모르겠습니다. 제가 어떤 일을 당할 수 있을지 몰랐지만 아직은 아무래도 괜찮다고 생각하고 있습니다. 저희들도 제 말을\n"]}]}]}