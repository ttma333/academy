{"cells":[{"cell_type":"markdown","metadata":{"id":"YixrCxo8O8N_"},"source":["TPU 이외에 의존성 있는 패키지를 설치합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17100,"status":"ok","timestamp":1673481050639,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"0U3MeuPe4HkP","outputId":"f0e2a2cd-91ac-45ac-e67e-850f82747f5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ratsnlp\n","  Downloading ratsnlp-1.0.52-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flask-ngrok\u003e=0.0.25\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Collecting Korpora\u003e=0.2.0\n","  Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-lightning==1.6.1\n","  Downloading pytorch_lightning-1.6.1-py3-none-any.whl (582 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.5/582.5 KB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flask-cors\u003e=3.0.10\n","  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: flask\u003e=1.1.4 in /usr/local/lib/python3.8/dist-packages (from ratsnlp) (1.1.4)\n","Collecting transformers==4.10.0\n","  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (4.4.0)\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (4.64.1)\n","Requirement already satisfied: packaging\u003e=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (21.3)\n","Requirement already satisfied: torch\u003e=1.8.* in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (1.13.1+cu116)\n","Requirement already satisfied: PyYAML\u003e=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (6.0)\n","Collecting torchmetrics\u003e=0.4.1\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard\u003e=2.2.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (2.9.1)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,\u003e=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (2022.11.0)\n","Requirement already satisfied: numpy\u003e=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning==1.6.1-\u003eratsnlp) (1.21.6)\n","Collecting pyDeprecate\u003c0.4.0,\u003e=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Collecting tokenizers\u003c0.11,\u003e=0.10.1\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2.25.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting huggingface-hub\u003e=0.0.12\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0-\u003eratsnlp) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.10.0-\u003eratsnlp) (3.9.0)\n","Requirement already satisfied: click\u003c8.0,\u003e=5.1 in /usr/local/lib/python3.8/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (7.1.2)\n","Requirement already satisfied: Werkzeug\u003c2.0,\u003e=0.15 in /usr/local/lib/python3.8/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.0.1)\n","Requirement already satisfied: itsdangerous\u003c2.0,\u003e=0.24 in /usr/local/lib/python3.8/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (1.1.0)\n","Requirement already satisfied: Jinja2\u003c3.0,\u003e=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask\u003e=1.1.4-\u003eratsnlp) (2.11.3)\n","Requirement already satisfied: Six in /usr/local/lib/python3.8/dist-packages (from flask-cors\u003e=3.0.10-\u003eratsnlp) (1.15.0)\n","Requirement already satisfied: xlrd\u003e=1.2.0 in /usr/local/lib/python3.8/dist-packages (from Korpora\u003e=0.2.0-\u003eratsnlp) (1.2.0)\n","Collecting dataclasses\u003e=0.6\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (3.8.3)\n","Requirement already satisfied: MarkupSafe\u003e=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2\u003c3.0,\u003e=2.10.1-\u003eflask\u003e=1.1.4-\u003eratsnlp) (2.0.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging\u003e=17.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (3.0.9)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (1.24.3)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (2022.12.7)\n","Requirement already satisfied: chardet\u003c5,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers==4.10.0-\u003eratsnlp) (4.0.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (0.4.6)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (2.15.0)\n","Requirement already satisfied: protobuf\u003c3.20,\u003e=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (3.19.6)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (0.6.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (3.4.1)\n","Requirement already satisfied: grpcio\u003e=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.51.1)\n","Requirement already satisfied: setuptools\u003e=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.8.1)\n","Requirement already satisfied: wheel\u003e=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (0.38.4)\n","Requirement already satisfied: absl-py\u003e=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses-\u003etransformers==4.10.0-\u003eratsnlp) (1.2.0)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.8.2)\n","Requirement already satisfied: charset-normalizer\u003c3.0,\u003e=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (2.1.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (6.0.4)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (22.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.3.3)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (4.0.2)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-\u003efsspec[http]!=2021.06.0,\u003e=2021.05.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.3.1)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (5.2.1)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (4.9)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (0.2.8)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (6.0.0)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (3.11.0)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (0.4.8)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003e=2.2.0-\u003epytorch-lightning==1.6.1-\u003eratsnlp) (3.2.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=868f636e7bcec77e18d3c9068361506481063791d9654f25ebfd76e84c84be6a\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, dataclasses, sacremoses, pyDeprecate, torchmetrics, Korpora, huggingface-hub, transformers, flask-ngrok, flask-cors, pytorch-lightning, ratsnlp\n","Successfully installed Korpora-0.2.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 huggingface-hub-0.11.1 pyDeprecate-0.3.2 pytorch-lightning-1.6.1 ratsnlp-1.0.52 sacremoses-0.0.53 tokenizers-0.10.3 torchmetrics-0.11.0 transformers-4.10.0\n"]}],"source":["!pip install ratsnlp"]},{"cell_type":"markdown","metadata":{"id":"Skjaa0Gk6d_X"},"source":["# 구글 드라이브 연동하기\n","모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29246,"status":"ok","timestamp":1673481079877,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"QQCGKzLXJuED","outputId":"141a2624-3ae8-4d1f-a406-0bd9586b01f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjcVcwm5Pw44"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ML-ubp246uzI"},"source":["# 각종 설정\n","모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5849,"status":"ok","timestamp":1673481179448,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"dtoPBSH4v31j"},"outputs":[],"source":["import torch\n","from ratsnlp.nlpbook.qa import QATrainArguments\n","args = QATrainArguments(\n","    pretrained_model_name=\"beomi/kcbert-large\",\n","    downstream_corpus_name=\"korquad-v1\",\n","    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-qa3\",\n","    max_seq_length=128,\n","    max_query_length=32,\n","    doc_stride=64,\n","    batch_size=32 if torch.cuda.is_available() else 4,\n","    learning_rate=5e-5,\n","    epochs=3,\n","    tpu_cores=0 if torch.cuda.is_available() else 8,\n","    seed=7,\n",")"]},{"cell_type":"markdown","metadata":{"id":"48RjaTAr7D4M"},"source":["# 랜덤 시드 고정\n","학습 재현을 위해 랜덤 시드를 고정합니다."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480,"status":"ok","timestamp":1673481194041,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"HuacSUSd7JRf","outputId":"224e31ae-19e4-46d0-b972-9a83487cced4"},"outputs":[{"name":"stdout","output_type":"stream","text":["set seed: 7\n"]}],"source":["from ratsnlp import nlpbook\n","nlpbook.set_seed(args)"]},{"cell_type":"markdown","metadata":{"id":"FeTvf0bc9bbV"},"source":["# 로거 설정\n","메세지 출력 등을 위한 logger를 설정합니다."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":471,"status":"ok","timestamp":1673481202020,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"251gdehZ9iPZ","outputId":"023c51d3-ddef-4dfc-d83a-b2ea2bd00c25"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:ratsnlp:Training/evaluation parameters QATrainArguments(pretrained_model_name='beomi/kcbert-large', downstream_corpus_name='korquad-v1', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-qa3', max_seq_length=128, doc_stride=64, max_query_length=32, threads=4, cpu_workers=2, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, fp16=False, tpu_cores=0, tqdm_enabled=True)\n","INFO:ratsnlp:Training/evaluation parameters QATrainArguments(pretrained_model_name='beomi/kcbert-large', downstream_corpus_name='korquad-v1', downstream_corpus_root_dir='/content/Korpora', downstream_model_dir='/gdrive/My Drive/nlpbook/checkpoint-qa3', max_seq_length=128, doc_stride=64, max_query_length=32, threads=4, cpu_workers=2, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=3, batch_size=32, fp16=False, tpu_cores=0, tqdm_enabled=True)\n"]}],"source":["nlpbook.set_logger(args)"]},{"cell_type":"markdown","metadata":{"id":"DqUazvWL7Pry"},"source":["# 말뭉치 다운로드\n","실습에 사용할 말뭉치(KorQuAD-V1)를 다운로드합니다."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2084,"status":"ok","timestamp":1673481217917,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"opyaJgPA7Zxi","outputId":"467752a3-b46a-4db2-b78a-ece916b13034"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 38.5MB [00:00, 80.3MB/s]\n","Downloading: 3.88MB [00:00, 72.5MB/s]                  \n"]}],"source":["nlpbook.download_downstream_dataset(args)"]},{"cell_type":"markdown","metadata":{"id":"2DnwLCKB7cRq"},"source":["# 토크나이저 준비\n","토큰화를 수행하는 토크나이저를 선언합니다"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113},"executionInfo":{"elapsed":10611,"status":"ok","timestamp":1673481233885,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"OlcoBivi7hIY","outputId":"2329e554-bb81-416a-ec62-a8dc429cc252"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d81bae1de62d412fb3837eee1bcd131e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/250k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1859e0db4af643b0904dcddf7a378544","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/49.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3d5e1534f5841aeb88f95c2115a6a53","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/672 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained(\n","    args.pretrained_model_name,\n","    do_lower_case=False,\n",")"]},{"cell_type":"markdown","metadata":{"id":"hZbLCM5e7i6g"},"source":["# 학습데이터 구축\n","학습데이터를 만듭니다."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368452,"status":"ok","timestamp":1673481602333,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"v9s8znA17ovP","outputId":"c93e68eb-c994-4121-810b-456f34f771be"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:ratsnlp:Creating features from train dataset file at /content/Korpora/korquad-v1\n","INFO:ratsnlp:Creating features from train dataset file at /content/Korpora/korquad-v1\n","100%|██████████| 1420/1420 [00:00\u003c00:00, 19492.62it/s]\n","convert squad examples to features: 100%|██████████| 57688/57688 [05:31\u003c00:00, 174.16it/s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:answer: 교 ##향 ##곡\n","INFO:ratsnlp:answer: 교 ##향 ##곡\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=45, end_positions=47)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=45, end_positions=47)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트를 읽고 무엇을 쓰고 ##자 했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 19143, 13985, 12449, 9194, 4105, 3385, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 18 ##3 ##9년 바 ##그 ##너 ##는 괴 ##테 ##의 파 ##우스 ##트 ##을 처음 읽고 그 내용 ##에 마음이 끌려 이를 소재 ##로 해서 하나의 교 ##향 ##곡 ##을 쓰 ##려는 뜻을 갖 ##는다 . 이 시기 바 ##그 ##너 ##는 18 ##3 ##8년 ##에 빛 독 ##촉 ##으로 산 ##전 ##수 ##전을 다 걲 ##은 상황이 ##라 좌 ##절 ##과 실망 ##에 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 8601, 4633, 29697, 1480, 4313, 4538, 4008, 336, 4065, 4042, 3231, 23243, 4104, 4027, 8793, 13985, 391, 9132, 4113, 10966, 11728, 12023, 14657, 4091, 8598, 16639, 341, 4573, 4771, 4027, 2139, 8478, 14416, 214, 8202, 17, 2451, 13007, 1480, 4313, 4538, 4008, 8601, 4633, 22903, 4113, 1676, 868, 4913, 7965, 1789, 4203, 4110, 15031, 786, 250, 4057, 10878, 4007, 2593, 4094, 4128, 10289, 4113, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 가득 ##했 ##으며 메 ##피 ##스 ##토 ##펠 ##레스 ##를 만나는 파 ##우스 ##트 ##의 심 ##경 ##에 공감 ##했다고 한다 . 또한 파리 ##에서 아 ##브 ##네 ##크 ##의 지휘 ##로 파리 음악 ##원 관 ##현 ##악 ##단이 연 ##주 ##하는 베 ##토 ##벤 ##의 교 ##향 ##곡 9 ##번 ##을 듣고 깊은 감 ##명을 받았는데 , 이것이 이 ##듬 ##해 1월 ##에 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10958, 4062, 9511, 1355, 4600, 4103, 4775, 5602, 10770, 4180, 26732, 3231, 23243, 4104, 4042, 2015, 4012, 4113, 9198, 8763, 8129, 17, 10384, 23008, 7971, 2170, 4408, 4011, 4147, 4042, 17015, 4091, 23008, 21056, 4165, 323, 4175, 4158, 11413, 2273, 4043, 7966, 1543, 4775, 4170, 4042, 341, 4573, 4771, 28, 4566, 4027, 10599, 18907, 208, 9504, 24835, 15, 11060, 2451, 4780, 4032, 18548, 4113, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 파 ##우스 ##트 ##의 서 ##곡 ##으로 쓰여 ##진 이 작품 ##에 조금이라도 영향을 끼 ##쳤 ##으리 ##라는 것은 의심 ##할 여지가 없다 . 여기 ##의 라 ##단 ##조 조성 ##의 경우 ##에도 그의 전기 ##에 적 ##혀 있는 것처럼 단순한 정신적 피로 ##나 실 ##의가 반영 ##된 것이 아니라 베 ##토 ##벤 ##의 합 ##창 ##교 ##향 ##곡 조성 ##의 영향을 받은 것을 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( [SEP]\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=108, end_positions=110)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 3231, 23243, 4104, 4042, 1843, 4771, 7965, 28987, 4153, 2451, 15489, 4113, 13928, 17283, 575, 4261, 26783, 8114, 8852, 9107, 4082, 28498, 8131, 17, 8225, 4042, 1114, 4281, 4194, 17138, 4042, 9961, 8222, 14041, 10892, 4113, 2524, 4443, 8032, 12710, 21602, 18625, 24569, 4136, 2009, 11012, 17068, 4130, 8544, 8141, 1543, 4775, 4170, 4042, 3367, 4183, 4267, 4573, 4771, 17138, 4042, 17283, 9838, 9153, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=108, end_positions=110)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] 볼 수 있다 . 그렇게 교 ##향 ##곡 작 ##곡 ##을 18 ##3 ##9년 ##부터 40년 ##에 걸 ##쳐 파리 ##에서 착 ##수 ##했 ##으나 1 ##악 ##장을 쓴 뒤에 중단 ##했다 . 또한 작품 ##의 완성 ##과 동시에 그는 이 서 ##곡 ( 1 ##악 ##장 ) 을 파리 음악 ##원의 연 ##주 ##회에서 연 ##주 ##할 파 ##트 ##보 ##까지 준비 ##하였 ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 [SEP]\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:answer: 1 ##악 ##장을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=44, end_positions=46)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 1576, 1931, 8120, 17, 8117, 341, 4573, 4771, 2478, 4771, 4027, 8601, 4633, 29697, 8042, 25305, 4113, 254, 4133, 23008, 7971, 2840, 4110, 4062, 10410, 20, 4158, 8915, 2141, 11726, 13014, 8258, 17, 10384, 15489, 4042, 16520, 4128, 15831, 20048, 2451, 1843, 4771, 11, 20, 4158, 4099, 12, 2424, 23008, 21056, 18639, 2273, 4043, 27703, 2273, 4043, 4082, 3231, 4104, 4010, 7999, 9242, 22504, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=44, end_positions=46)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question \u0026 context: [CLS] 바 ##그 ##너 ##는 교 ##향 ##곡 작 ##곡 ##을 어디까지 쓴 뒤에 중단 ##했 ##는가 ? [SEP] ##으나 , 실제로는 이루어 ##지지 ##는 않았다 . 결국 초 ##연 ##은 4년 반 ##이 지난 후에 드 ##레스 ##덴 ##에서 연 ##주 ##되었고 재 ##연 ##도 이루어 ##졌지 ##만 , 이후에 그대로 방치 ##되고 말았 ##다 . 그 사이에 그는 리 ##엔 ##치 ##와 방 ##황 ##하는 네 ##덜 ##란드 ##인을 완성 ##하고 탄 ##호 ##이 ##저 ##에도 착 ##수 ##하는 등 분 ##주 ##한 시간을 보냈 ##는데 , 그런 바쁜 생활 ##이 이 곡 ##을 잊 ##게 한 것이 아닌가 하는 의견 ##도 있다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 1480, 4313, 4538, 4008, 341, 4573, 4771, 2478, 4771, 4027, 13655, 2141, 11726, 13014, 4062, 9411, 32, 3, 10410, 15, 26271, 11877, 8840, 4008, 12626, 17, 8340, 2906, 4132, 4057, 16243, 1483, 4017, 9403, 14180, 947, 10770, 5076, 7971, 2273, 4043, 24984, 2499, 4132, 4029, 11877, 23679, 4049, 15, 22395, 9341, 14218, 8593, 19696, 4020, 17, 391, 19237, 20048, 1279, 4484, 4077, 4196, 1497, 4432, 7966, 654, 4181, 27028, 9700, 16520, 7968, 3110, 4319, 4017, 4488, 8222, 2840, 4110, 7966, 963, 1614, 4043, 4047, 16381, 13079, 7972, 15, 8053, 15118, 9683, 4017, 2451, 304, 4027, 2471, 4199, 3354, 8544, 8260, 7996, 10040, 4029, 8120, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_train_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 35.802 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_train_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 35.802 s]\n"]}],"source":["from ratsnlp.nlpbook.qa import KorQuADV1Corpus, QADataset\n","from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n","corpus = KorQuADV1Corpus()\n","train_dataset = QADataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"train\",\n",")\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    sampler=RandomSampler(train_dataset, replacement=False),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")"]},{"cell_type":"markdown","metadata":{"id":"SOAACuBY7vem"},"source":["# 테스트 데이터 구축\n","학습 중에 평가할 테스트 데이터를 구축합니다."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35441,"status":"ok","timestamp":1673481637761,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"mcm1tgfq7y84","outputId":"4ef444c0-4c0f-4611-8f93-cb9dacae0653"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:ratsnlp:Creating features from val dataset file at /content/Korpora/korquad-v1\n","INFO:ratsnlp:Creating features from val dataset file at /content/Korpora/korquad-v1\n","100%|██████████| 140/140 [00:00\u003c00:00, 11825.89it/s]\n","convert squad examples to features: 100%|██████████| 5533/5533 [00:31\u003c00:00, 175.32it/s]\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:answer: 임 ##수 ##경을\n","INFO:ratsnlp:answer: 임 ##수 ##경을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=75, end_positions=77)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=75, end_positions=77)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 6월 30 ##일 평양 ##축 ##전에 대표로 파견 된 인물 ##은 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 23343, 8476, 4046, 14601, 4728, 8409, 24345, 20158, 902, 10393, 4057, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##을 검 ##거 ##한 장소 ##는 경 ##희 ##대 내 어디 ##인가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: 학생 ##회 ##관 건물 계 ##단을\n","INFO:ratsnlp:answer: 학생 ##회 ##관 건물 계 ##단을\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=61, end_positions=66)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4027, 255, 4014, 4047, 25754, 4008, 291, 4346, 4140, 609, 8118, 8078, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=61, end_positions=66)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 ##분 경 가스 ##총 ##과 전자 ##봉 ##으로 무장 ##한 특 ##공 ##조 및 대 ##공 ##과 직원 12 ##명 등 22 ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 [SEP]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:answer: [CLS]\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 4192, 291, 18357, 4696, 4128, 12116, 4694, 7965, 14050, 4047, 3210, 4239, 4194, 1476, 809, 4239, 4128, 9736, 9685, 4268, 963, 15190, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=0, end_positions=0)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:question \u0026 context: [CLS] 임종석 ##이 조사를 받은 뒤 인 ##계 ##된 곳은 어딘 ##가 ? [SEP] ##명의 사 ##복 경찰을 승 ##용 ##차 8 ##대에 나누어 경 ##희 ##대학 ##교 ##에 투입 ##했다 . 198 ##9년 12월 18 ##일 오전 8 ##시 15 ##분 경 서울 ##청 ##량 ##리 ##경찰 ##서는 호위 학생 5 ##명 ##과 함께 경 ##희 ##대학 ##교 학생 ##회 ##관 건물 계 ##단을 내려오 ##는 임종석 ##을 발견 , 검 ##거 ##해 구속 ##을 집행 ##했다 . 임종석 ##은 청 ##량 ##리 ##경찰 ##서에 ##서 약 1시간 동안 조사를 받은 뒤 오전 9 ##시 50 ##분 경 서울 장 ##안 ##동의 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로 인 ##계 ##되었다 . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","INFO:ratsnlp:answer: 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로\n","INFO:ratsnlp:answer: 서울 ##지 ##방 ##경찰 ##청 공안 ##분 ##실로\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=103, end_positions=110)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 14749, 4017, 15576, 9838, 934, 2454, 4067, 4130, 17885, 16375, 4009, 32, 3, 12418, 1785, 4232, 21041, 1991, 4429, 4495, 27, 10883, 26039, 291, 4346, 12839, 4267, 4113, 13333, 8258, 17, 25704, 29697, 25604, 8601, 4046, 28970, 27, 4039, 9138, 4192, 291, 8270, 4190, 4667, 4038, 11304, 9666, 24226, 8842, 24, 4268, 4128, 9158, 291, 4346, 12839, 4267, 8842, 4375, 4337, 10828, 296, 13321, 13851, 4008, 14749, 4027, 14384, 15, 255, 4014, 4032, 8430, 4027, 11932, 8258, 17, 14749, 4057, 2883, 4667, 4038, 11304, 14029, 4072, 2208, 20600, 10921, 15576, 9838, 934, 28970, 28, 4039, 8583, 4192, 291, 8270, 2492, 4061, 21643, 8270, 4102, 4015, 11304, 4190, 13445, 4192, 24442, 2454, 4067, 14012, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], start_positions=103, end_positions=110)\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:*** Example ***\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 사람의 이름은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 [SEP]\n","INFO:ratsnlp:question \u0026 context: [CLS] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ##로 지명 ##수 ##배 ##된 사람의 이름은 ? [SEP] 198 ##9년 2월 15일 여의도 농민 폭력 시위를 주도 ##한 혐의 ( 폭력 ##행위 ##등 ##처벌 ##에 ##관 ##한 ##법 ##률 ##위반 ) 으로 지명 ##수 ##배 ##되었다 . 198 ##9년 3월 12 ##일 서울 ##지 ##방 ##검찰 ##청 공안 ##부는 임종석 ##의 사전 ##구속 ##영장 ##을 발부 ##받았 ##다 . 같은 해 6월 30 ##일 평양 ##축 ##전에 임 ##수 ##경을 대표로 파견 ##하여 국가보안법 ##위반 혐의가 추가 ##되었다 . 경찰은 12월 18 ##일 ~ 20 ##일 사이 서울 경 ##희 ##대학 ##교 ##에서 임종석 ##이 성 ##명 발표 ##를 추진 ##하고 있다는 첩 ##보를 입 ##수 ##했고 , 12월 18 ##일 오전 7시 40 [SEP]\n","INFO:ratsnlp:answer: 임종석\n","INFO:ratsnlp:answer: 임종석\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 4091, 23985, 4110, 4200, 4130, 12162, 25542, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=62, end_positions=62)\n","INFO:ratsnlp:features: QAFeatures(input_ids=[2, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 4091, 23985, 4110, 4200, 4130, 12162, 25542, 32, 3, 25704, 29697, 18163, 26757, 20604, 29804, 10901, 25099, 13225, 4047, 16704, 11, 10901, 12175, 4086, 11417, 4113, 4337, 4047, 4021, 4486, 14273, 12, 10442, 23985, 4110, 4200, 14012, 17, 25704, 29697, 18306, 9685, 4046, 8270, 4102, 4015, 10299, 4190, 13445, 11090, 14749, 4042, 11202, 13140, 18936, 4027, 28095, 14930, 4020, 17, 8066, 3376, 23343, 8476, 4046, 14601, 4728, 8409, 2465, 4110, 19033, 24345, 20158, 8455, 29442, 14273, 25419, 11368, 14012, 17, 14270, 25604, 8601, 4046, 95, 8255, 4046, 8538, 8270, 291, 4346, 12839, 4267, 7971, 14749, 4017, 1856, 4268, 9765, 4180, 12166, 7968, 9340, 2880, 17535, 2466, 4110, 9851, 15, 25604, 8601, 4046, 28970, 22074, 8914, 3], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], start_positions=62, end_positions=62)\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file, it could take a lot of time...\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_val_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 3.383 s]\n","INFO:ratsnlp:Saving features into cached file /content/Korpora/korquad-v1/cached_val_BertTokenizer_maxlen-128_maxquerylen-32_docstride-64_korquad-v1_question-answering [took 3.383 s]\n"]}],"source":["val_dataset = QADataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"val\",\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    sampler=SequentialSampler(val_dataset),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=args.cpu_workers,\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"HztMCywb70e9"},"source":["# 모델 초기화\n","프리트레인이 완료된 BERT 모델을 읽고, 질의 응답을 수행할 모델을 초기화합니다."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1319,"status":"ok","timestamp":1673483003574,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"ohOlRdP18GVe"},"outputs":[],"source":["from transformers import BertConfig\n","pretrained_model_config = BertConfig.from_pretrained(\n","    args.pretrained_model_name,\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":29553,"status":"ok","timestamp":1673483106626,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"staYwMx88MWQ","outputId":"696a22cb-e0c4-4995-b593-6fd45cc2aa0a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a71e6e69ee7471ab2e11192682fdb72","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.34G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at beomi/kcbert-large were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at beomi/kcbert-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForQuestionAnswering\n","model = BertForQuestionAnswering.from_pretrained(\n","        args.pretrained_model_name,\n","        config=pretrained_model_config,\n",")"]},{"cell_type":"markdown","metadata":{"id":"lYtJXijM8PN8"},"source":["# 학습 준비\n","Task와 Trainer를 준비합니다."]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1673483106627,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"-FFn4MSz8SWu"},"outputs":[],"source":["from ratsnlp.nlpbook.qa import QATask\n","task = QATask(model, args)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1673483110123,"user":{"displayName":"kevin park","userId":"02703084888761299921"},"user_tz":-540},"id":"18W4vRtR8UTx","outputId":"8efe49f1-252f-47ad-e974-548e4966e984"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True, used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}],"source":["trainer = nlpbook.get_trainer(args)"]},{"cell_type":"markdown","metadata":{"id":"KteHdhBT8X0e"},"source":["# 학습\n","준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-qa`)에 저장됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":344},"id":"SDr3M_nF8l7M"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /gdrive/My Drive/nlpbook/checkpoint-qa3/lightning_logs\n","INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.8/dist-packages/pytorch_lightning/core/optimizer.py:380: RuntimeWarning: Found unsupported keys in the optimizer configuration: {'scheduler'}\n","  rank_zero_warn(\n","INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name  | Type                     | Params\n","---------------------------------------------------\n","0 | model | BertForQuestionAnswering | 333 M \n","---------------------------------------------------\n","333 M     Trainable params\n","0         Non-trainable params\n","333 M     Total params\n","1,333.371 Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"557b2e2c33fb49199d54bcf3a858f59b","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e748903076d4ccdb3eff280bb1599f9","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"915c4cefadfd41d3bd4d9db4b69233eb","version_major":2,"version_minor":0},"text/plain":["Validation: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.fit(\n","    task,\n","    train_dataloaders=train_dataloader,\n","    val_dataloaders=val_dataloader,\n",")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"https://github.com/ratsgo/nlpbook/blob/master/examples/question_answering/train_colab.ipynb","timestamp":1673052208828}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0a71e6e69ee7471ab2e11192682fdb72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8f30f02aa1045b9945741bcd355c4aa","IPY_MODEL_8dc1e2ec64a7460693c3d9e81ae09bf4","IPY_MODEL_9bce059d3daa4e1781981f634e984fa7"],"layout":"IPY_MODEL_f82f79b575af45b496db29c7008bc6b6"}},"0b2b17477f984f59b46bf396ed9a7ce5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_96eb7a87dd5d449aacb0ea40d10c2b56","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83613fb3d828404faedff0fdb0ca91fc","value":1}},"0c6a9743f28048f48343e7c98436f712":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c5d5690ffbe4936880fdd676ca3ae80","max":672,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e754ce9a28734640bf99ed7db36f0f62","value":672}},"13459bdd44d94804a83640ead0982996":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1859e0db4af643b0904dcddf7a378544":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_447d970a9b5d4ddc892571258cfecbfe","IPY_MODEL_53de0fb47897461aad73d68ecd68a8ee","IPY_MODEL_cc63b647599b483396e66497f242ee9e"],"layout":"IPY_MODEL_f0f607b072e5454599afec7253edab28"}},"1b598eef9a844b3bb1ede9c9b5879676":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cec058cff65407b8e7da4b5adac78b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f529df4c970484bb6b0f6e1235c6651":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c35888d4e6417a8f52d779eb84b48d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_766f877c653f4227a2614225f18421c7","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c9f58edb54bf4791abde25a5d9d23590","value":1}},"280dab5b4cdb418eb476ddfb66402099":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c08046495db84cdd9522aa266263ae44","placeholder":"​","style":"IPY_MODEL_f85d279204654d2e8ce8707bb21e3bc4","value":"Validation DataLoader 0: 100%"}},"2ce4d468571c4f998db104518c3aeee6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_67a9cd733bc847c98f91e5c8b93bd99f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c30fd7c74af46ec908d1bb00aacd052","value":1}},"2cf76b55a5414cd5843c49a61677916b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b578e284fd064d0dad0f7f9789e7f5e7","placeholder":"​","style":"IPY_MODEL_fdda70d77aec44fa8b274c16662a9cca","value":" 672/672 [00:00\u0026lt;00:00, 32.3kB/s]"}},"2e748903076d4ccdb3eff280bb1599f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_280dab5b4cdb418eb476ddfb66402099","IPY_MODEL_26c35888d4e6417a8f52d779eb84b48d","IPY_MODEL_8482644e1c8c43ea9d943b200289fffe"],"layout":"IPY_MODEL_f5665f536d7a4bc39b989835ed0608a5"}},"33f9a76f816140a5b6aa7b6e65b62d89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35114c3d4de14a79805225cd81779be7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_820267565bf24ce5a5f2769beb743ccf","placeholder":"​","style":"IPY_MODEL_61af8e20ffc34feda1124f1a2de1852f","value":" 7061/7688 [8:34:56\u0026lt;45:43,  4.38s/it, loss=0.278, v_num=0, acc=1.000, val_loss=0.411, val_acc=0.878]"}},"447d970a9b5d4ddc892571258cfecbfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69b106176fcd45748d2d009af6373e25","placeholder":"​","style":"IPY_MODEL_8191909dfb4e4b09a6d4cfc7942ac84f","value":"Downloading: 100%"}},"45091d0052f24a2fb45bf918a487dad8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48294e454a9344328ccff4cc01950875":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"494132d0437d4ced9da72029beeffeda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c5d5690ffbe4936880fdd676ca3ae80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5362fa6058474b56aca1b549e9e1044f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45091d0052f24a2fb45bf918a487dad8","placeholder":"​","style":"IPY_MODEL_63b67d51a89843dcbf341e14f14b5d11","value":" 64/691 [00:43\u0026lt;07:06,  1.47it/s]"}},"53de0fb47897461aad73d68ecd68a8ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da399e9939d44d239248f595cee153b5","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58a6bd18364045a399b355726e6a6149","value":49}},"557b2e2c33fb49199d54bcf3a858f59b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8516a172629d4c39b22c462af89065ee","IPY_MODEL_2ce4d468571c4f998db104518c3aeee6","IPY_MODEL_35114c3d4de14a79805225cd81779be7"],"layout":"IPY_MODEL_c30d3955cadb4a8baaffd35d958de2b2"}},"57dd74d623b141fc905558cdd8e303bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58a6bd18364045a399b355726e6a6149":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e64f55e6f6145feaefd83e65bc014d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca7021c997bc4c3a9e2814e9dc34c21e","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1cec058cff65407b8e7da4b5adac78b8","value":249928}},"61af8e20ffc34feda1124f1a2de1852f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63b67d51a89843dcbf341e14f14b5d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67a9cd733bc847c98f91e5c8b93bd99f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69b106176fcd45748d2d009af6373e25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6af51710d8d144dba5d813c63fbe1dc2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"716d4ffe912645c88cb693262ef587cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93f553137904ea193f6a52f87493eb0","placeholder":"​","style":"IPY_MODEL_494132d0437d4ced9da72029beeffeda","value":"Downloading: 100%"}},"741959194c6b4c47b6ef34ce1327eab9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"766f877c653f4227a2614225f18421c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"775ccfdfb03b4dfc85a7e282a228c508":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c30fd7c74af46ec908d1bb00aacd052":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8191909dfb4e4b09a6d4cfc7942ac84f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"820267565bf24ce5a5f2769beb743ccf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82d359ed0b3a41ef9a66990f353e219b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f529df4c970484bb6b0f6e1235c6651","placeholder":"​","style":"IPY_MODEL_84595dc53d164015bfcd22fc50a76c97","value":"Downloading: 100%"}},"83613fb3d828404faedff0fdb0ca91fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84595dc53d164015bfcd22fc50a76c97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8482644e1c8c43ea9d943b200289fffe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be982e6962a044379c33b9cafc14308f","placeholder":"​","style":"IPY_MODEL_57dd74d623b141fc905558cdd8e303bd","value":" 691/691 [07:57\u0026lt;00:00,  1.45it/s]"}},"8516a172629d4c39b22c462af89065ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eac83f65baad439b84b27854670e4a68","placeholder":"​","style":"IPY_MODEL_1b598eef9a844b3bb1ede9c9b5879676","value":"Epoch 1:  92%"}},"8dc1e2ec64a7460693c3d9e81ae09bf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2a8f98e3990460fa09db7526f681e58","max":1341992121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9515ceabed3418d940898781676cde4","value":1341992121}},"915c4cefadfd41d3bd4d9db4b69233eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_caa0a8577ed04ab096d1c35235fe94e6","IPY_MODEL_0b2b17477f984f59b46bf396ed9a7ce5","IPY_MODEL_5362fa6058474b56aca1b549e9e1044f"],"layout":"IPY_MODEL_741959194c6b4c47b6ef34ce1327eab9"}},"968c2814472c4822aeb91e201a12ea98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96eb7a87dd5d449aacb0ea40d10c2b56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bce059d3daa4e1781981f634e984fa7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7c687740af9486ca3af6a2c7deb6eef","placeholder":"​","style":"IPY_MODEL_33f9a76f816140a5b6aa7b6e65b62d89","value":" 1.34G/1.34G [00:21\u0026lt;00:00, 39.3MB/s]"}},"a14d545f44f64f2cad3ac6e1d4f3caba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3d5e1534f5841aeb88f95c2115a6a53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82d359ed0b3a41ef9a66990f353e219b","IPY_MODEL_0c6a9743f28048f48343e7c98436f712","IPY_MODEL_2cf76b55a5414cd5843c49a61677916b"],"layout":"IPY_MODEL_13459bdd44d94804a83640ead0982996"}},"a7727aced9634c3488069e3f066e64a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93f553137904ea193f6a52f87493eb0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9515ceabed3418d940898781676cde4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b578e284fd064d0dad0f7f9789e7f5e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be982e6962a044379c33b9cafc14308f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c08046495db84cdd9522aa266263ae44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c30d3955cadb4a8baaffd35d958de2b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"c7c687740af9486ca3af6a2c7deb6eef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8eb1f0dc95a48a6a53ffd6e1aa234ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9f58edb54bf4791abde25a5d9d23590":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca7021c997bc4c3a9e2814e9dc34c21e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa0a8577ed04ab096d1c35235fe94e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffac04ccde1a4b30988e4dce14d99ee8","placeholder":"​","style":"IPY_MODEL_775ccfdfb03b4dfc85a7e282a228c508","value":"Validation DataLoader 0:   9%"}},"cc63b647599b483396e66497f242ee9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_968c2814472c4822aeb91e201a12ea98","placeholder":"​","style":"IPY_MODEL_a14d545f44f64f2cad3ac6e1d4f3caba","value":" 49.0/49.0 [00:00\u0026lt;00:00, 2.92kB/s]"}},"d81bae1de62d412fb3837eee1bcd131e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_716d4ffe912645c88cb693262ef587cb","IPY_MODEL_5e64f55e6f6145feaefd83e65bc014d1","IPY_MODEL_ff248d79e2074f9ba580eeae9ca034b2"],"layout":"IPY_MODEL_c8eb1f0dc95a48a6a53ffd6e1aa234ce"}},"da399e9939d44d239248f595cee153b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a8f98e3990460fa09db7526f681e58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e754ce9a28734640bf99ed7db36f0f62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8f30f02aa1045b9945741bcd355c4aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7727aced9634c3488069e3f066e64a3","placeholder":"​","style":"IPY_MODEL_6af51710d8d144dba5d813c63fbe1dc2","value":"Downloading: 100%"}},"eac83f65baad439b84b27854670e4a68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0f607b072e5454599afec7253edab28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5665f536d7a4bc39b989835ed0608a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"f82f79b575af45b496db29c7008bc6b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f85d279204654d2e8ce8707bb21e3bc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdda70d77aec44fa8b274c16662a9cca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff248d79e2074f9ba580eeae9ca034b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff56dca2545c4653a394dae7b23a0f7f","placeholder":"​","style":"IPY_MODEL_48294e454a9344328ccff4cc01950875","value":" 250k/250k [00:00\u0026lt;00:00, 277kB/s]"}},"ff56dca2545c4653a394dae7b23a0f7f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ffac04ccde1a4b30988e4dce14d99ee8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}